{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Analyze a very simple dataset with LDA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import adso\nimport matplotlib.pyplot as plt\nimport nltk\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "set seed\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adso.set_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download the dataset and select 1000 random elements\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = adso.data.load_labelled_test_dataset(lines=True)\n\nprint(\"Number of documents: \", len(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tokenize the dataset using a stemmer and a stopwords list, removing punctation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adso.transform.nltk_download(\"stopwords\")\n\nsnowball = nltk.stem.snowball.SnowballStemmer(\"english\")\n\n\ndef stemmer(word):\n    ret = snowball.stem(word)\n    if ret.isalpha():\n        return ret\n    else:\n        return None\n\n\ntokenizer = adso.transform.Tokenizer(\n    stemmer=stemmer,\n    stopwords=nltk.corpus.stopwords.words(\"english\") + [None],\n)\n\ntokens = tokenizer.fit_transform(data)\n\nprint(\"First ten tokens of the first document:\")\nprint(tokens[0][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transform the list of tokens in a list of numbers.\nWe will use the absolute frequency.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vectorizer = adso.transform.CountVectorizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate the vocabulary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vectorizer.fit(tokens)\nvocab = vectorizer.vocab\n\nprint(\"Number of words in vocabulary: \", len(vocab))\n\nprint(\"index of word 'bird': \", vocab[\"bird\"])\nprint(\"word at index 1: \", vocab[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the count matrices from tokens.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "count_matrix = vectorizer.transform(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LDA\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "LDA = adso.topicmodel.LDA(n_topic=4, tolerance=1e-3, max_iter=200)\nret = LDA.fit_transform(count_matrix)\nestimation = ret[0]\nbeta = ret[2]\nprint(\"LDA ended after\", ret[6], \"iterations, achiving a loglikelihood of\", ret[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the 10 most characteristic words for each topic\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for i in range(4):\n    print(\"10 most characteristic words of topic\", i)\n    print(\n        list(\n            map(\n                lambda j: vocab[j],\n                np.argsort(np.squeeze(-beta[i, :].toarray()))[:10].tolist(),\n            )\n        )\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the confusion matrix (not diagonalized)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(beta.todense())\nprint(estimation.todense())\n\npredicted_topic = np.argmax(estimation, axis=1)\n\nlistvectorizer = adso.transform.ListVectorizer()\nlabels = list(map(lambda l: [l], data.get_labels()))\n\nlabel_topic = np.squeeze(listvectorizer.fit_transform(labels))\n\nconfusion = np.zeros((4, 4))\nfor i in zip(label_topic, predicted_topic):\n    confusion[i] += 1\n\nfig, ax = plt.subplots()\nax.imshow(confusion)\nax.set_xticks(np.arange(4))\nax.set_yticks(np.arange(4))\nax.set_yticklabels(list(listvectorizer.vocab.stoi.keys()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}