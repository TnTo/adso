{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Analyze the 20newsgroups dataset with LDA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "import\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import random\n\nimport adso\nimport matplotlib.pyplot as plt\nimport nltk\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "set seed\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adso.set_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download the dataset and select 1000 random elements\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = adso.data.load_20newsgroups(split=\"test\")\n\nnew_data = []\nfor i in random.sample(range(len(data)), k=1000):\n    new_data.append(data[i])\ndata = adso.data.LabelledDataset(new_data)\n\nprint(\"Number of documents: \", len(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tokenize the dataset using a stemmer and a stopwords list, removing punctation\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "adso.transform.nltk_download(\"stopwords\")\n\nsnowball = nltk.stem.snowball.SnowballStemmer(\"english\")\n\n\ndef stemmer(word):\n    ret = snowball.stem(word)\n    if ret.isalpha():\n        return ret\n    else:\n        return None\n\n\ntokenizer = adso.transform.Tokenizer(\n    stemmer=stemmer,\n    stopwords=nltk.corpus.stopwords.words(\"english\") + [None],\n)\n\ntokens = tokenizer.fit_transform(data)\n\nprint(\"First ten tokens of the first document:\")\nprint(tokens[0][:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Transform the list of tokens in a list of numbers.\nWe will use the absolute frequency.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vectorizer = adso.transform.CountVectorizer(max_freq=0.7, min_freq=0.1, max_size=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate the vocabulary.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vectorizer.fit(tokens)\nvocab = vectorizer.vocab\n\nprint(\"Number of words in vocabulary: \", len(vocab))\n\nprint(\"index of word 'god': \", vocab[\"god\"])\nprint(\"word at index 52: \", vocab[52])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create the count matrices from tokens.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "count_matrix = vectorizer.transform(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LDA\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "LDA = adso.topicmodel.LDA(n_topic=20, tolerance=0.001, max_iter=100)\nret = LDA.fit_transform(count_matrix)\nestimation = ret[0]\nbeta = ret[2]\nprint(\"LDA ended after\", ret[6], \"iterations, achiving a loglikelihood of\", ret[5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check the 10 most characteristic words for each topic\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for i in range(20):\n    print(\"10 most characteristic words of topic\", i)\n    print(\n        list(\n            map(\n                lambda j: vocab[j],\n                np.argsort(np.squeeze(-beta[i, :].toarray()))[:10].tolist(),\n            )\n        )\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the confusion matrix (not diagonalized)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "predicted_topic = np.argmax(estimation, axis=1)\n\nlistvectorizer = adso.transform.ListVectorizer()\nlabels = list(map(lambda l: [l], data.get_labels()))\n\nlabel_topic = np.squeeze(listvectorizer.fit_transform(labels))\n\nconfusion = np.zeros((20, 20))\nfor i in zip(label_topic, predicted_topic):\n    confusion[i] += 1\n\nfig, ax = plt.subplots()\nax.imshow(confusion)\nax.set_xticks(np.arange(20))\nax.set_yticks(np.arange(20))\nax.set_yticklabels(list(listvectorizer.vocab.stoi.keys()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Print the confusion matrix skipping the first topic\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "confusion = confusion[:, 1:]\nfig, ax = plt.subplots()\nax.imshow(confusion)\nax.set_xticks(np.arange(19))\nax.set_yticks(np.arange(20))\nax.set_yticklabels(list(listvectorizer.vocab.stoi.keys()))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}