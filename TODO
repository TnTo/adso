# Future features

### General improvements
[ ] Add parallelization
[ ] [0.0.2] Allow online processing
[ ] (?) Move external file into the git repo
[ ] [0.0.2] Add sha ckeck for external ( (?) not NLTK) files
[ ] Write documentation with example, citation and guide
[ ] [0.0.2] Add progress print (like in NMF)
[ ] (?) NamedTuple as return type
[ ] [0.0.2] Correct Labelled in Labeled
[ ] [0.0.2] Consider logaritmic transformation

### Additional Topic Modellind algorithms
[ ] Smoothed LDA (Blei03a)
[ ] Symmetric LDA (Blei03a and Blei & Lafferty)
[ ] HDP (Teh, Jordan, Beal & Blei)
[ ] Gibb's sample LDA (Griffiths & Steyvers)
[ ] DTM Blei & Lafferty
[ ] hSBM (Gerlach, Peixoto & Altman)
[ ] TopicMapping (Lancichinetti, Amaral et al) (with InfoMap, Louvain and Leiden clustering algorithms)

### Additional feature
[ ] Implement stopwords method as in Gerlach, Shi, Amaral 2019
[ ] Allow more type for Dataset construction
[ ] Add save methods to transformer and topicmodel
[ ] [0.0.2] Implement metrics (p.e. perplexity Blei03a) and plot
[ ] (?) Create class for returned object (i.e. TermDocumentMatrix, TokenDataset, ...)
[ ] Syntetic corpora generative algorithms

### Additional datasets
[ ] [0.0.2] [Web->Kb](http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/)

### Improve compatibility
[ ] (?) Adopt torchtext compatible Dataset structure [GitHub repo](https://github.com/pytorch/text/tree/master/torchtext/experimental/datasets)
[ ] (?) Use numpy for Tokenizer
[ ] Move NLTK and requests as optional dependency
[ ] [0.0.2] Recover 3.6 compatibility by removing type hinting or using pre 3.7 annotations

### Algorithm-specific improvement
[ ] Investigate LDA sparsity
[ ] [0.0.2] Use sparse for NMF
[ ] [0.0.2] Allow to specify initial alpha for LDA
[ ] (?) Add type check in Dataset constructor
[ ] Enable list indexing for Dataset
[ ] [0.0.2] Allow to fit Vectorizer with a given Vocabulary
[ ] [0.0.2] Add a function to transform CountVectorizer output to {Freq,TFIDF}Vectorizer output
[x] Remove sparsity for NMF AHCLS algorithm -- Use sparse instead --
[ ] [0.0.2] Get labels as list of list
[ ] [0.0.2] Add get_label method to vocab
[ ] [0.0.2] Move new code for LDA in a new class
[ ] [0.0.2] LDA separate max_iter and max_iter_alpha
